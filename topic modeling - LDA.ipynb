{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b82ac8d0",
   "metadata": {},
   "source": [
    "## Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9122feb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Madridista\\anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py:14: DeprecationWarning: Please use `spmatrix` from the `scipy.sparse` namespace, the `scipy.sparse.base` namespace is deprecated.\n",
      "  from scipy.sparse.base import spmatrix\n",
      "C:\\Users\\Madridista\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:18: DeprecationWarning: Please use `line_search_wolfe2` from the `scipy.optimize` namespace, the `scipy.optimize.linesearch` namespace is deprecated.\n",
      "  from scipy.optimize.linesearch import line_search_wolfe2, line_search_wolfe1\n",
      "C:\\Users\\Madridista\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:18: DeprecationWarning: Please use `line_search_wolfe1` from the `scipy.optimize` namespace, the `scipy.optimize.linesearch` namespace is deprecated.\n",
      "  from scipy.optimize.linesearch import line_search_wolfe2, line_search_wolfe1\n",
      "C:\\Users\\Madridista\\anaconda3\\lib\\site-packages\\gensim\\matutils.py:24: DeprecationWarning: Please use `triu` from the `scipy.linalg` namespace, the `scipy.linalg.special_matrices` namespace is deprecated.\n",
      "  from scipy.linalg.special_matrices import triu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import pyLDAvis\n",
    "import gensim\n",
    "from pprint import pprint\n",
    "from tmtoolkit.topicmod.evaluate import metric_coherence_gensim\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af8dbf2",
   "metadata": {},
   "source": [
    "## Read the news article csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ca84000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976</td>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917</td>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text  Category\n",
       "0       1833  worldcom ex-boss launches defence lawyers defe...  business\n",
       "1        154  german business confidence slides german busin...  business\n",
       "2       1101  bbc poll indicates economic gloom citizens in ...  business\n",
       "3       1976  lifestyle  governs mobile choice  faster  bett...      tech\n",
       "4        917  enron bosses in $168m payout eighteen former e...  business"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('BBC News Train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba07216a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('could rivalry overshadow election  tony blair and gordon brown are desperately trying to stuff the genie of their rivalry back into the bottle.  along with any number of senior cabinet colleagues  they are insisting their only job is to win the next election and govern in the best interests of britain. it is a message they are aiming directly at their backbenchers who are becoming irritated and even unnerved by the continuing claims and counter claims surrounding this alleged rift. ian gibson  for example  urged the two men to stop squabbling  declaring:  for goodness sake  sometimes you have to rise above petulance and make sure that you do your job as effectively as you can.  those with slim majorities are particularly fearful that the rift could hit their own hopes of re-election. tony blair will seek to reassure labour mps on monday evening at their first meeting of the new year at westminster - a behind-closed doors meeting which gordon brown is thought likely to also attend to show unity.  meanwhile the likes of health secretary john reid and labour peer lord haskins are warning of the electoral dangers of allowing this soap opera to continue. and they have both warned the rival camps to stop spreading the poison. lord haskins even suggested mr blair should reinstate mr brown as the central figure in the election planning.  but this particular genie is unusually reluctant to return to captivity and many fear it is simply too late to repair the damage. they believe they will be fighting the next election with the sounds of open warfare between the two men ringing in their ears. and it matters little whether the rift is real or  as some try to suggest  simply the product of newspaper headlines and westminster gossip. few in westminster actually believe that  simply because the evidence appears to contradict it.  for example  the weekend s attempts by both men to play down the divisions failed to do the trick. even as they were both insisting on their unity of purpose and claiming they would not be swayed by newspaper stories  they still managed to stir the speculation with their comments.  mr blair talked about the  new  labour manifesto - a move which seemed calculated to irritate the chancellor  who has long rejected the label. and mr brown pointedly refused to deny claims the prime minister had reneged on a deal to hand him the premiership last year. that claim was repeated in robert peston s book  a book which amply demonstrates this corrosive downing street soap opera is nowhere near its final act.  for his part  mr brown insists his only motivation was to get labour re-elected.  the trouble is  both men have fallen short of offering simple  straightforward denials of the central claims. so they have both been accused of actually making matters worse by feeding the speculation with their own behaviour. the first thing to be said is that these suggestions have not come from nowhere. they started with and are sustained by  friends  of the two men. one only had to listen to the chancellor s friend and former spin chief charlie whelan last week to understand that there is a real anger from this camp at the prime minister s apparent attempts to confound mr brown s leadership ambitions. but it is not just public pronouncements from ex-aides.  there are whispered briefings to selected journalists from both sides. it is no secret in westminster  for example  that downing street believes the chancellor is indulging in a mammoth sulk and acting in a petty and deliberately provocative manner.  then there are the actions of the men themselves. gordon brown sets out what is seen as a rival manifesto then appears to embark on his own personal campaign. the prime minister responds by scheduling his monthly press conference to clash with a keynote speech by the chancellor. meanwhile large numbers of backbench mps insist voters are either entirely uninterested in the chatter  which they believe is a media-only obsession  or that they fear for the efficient running of a government beset by such rivalry. either way  there is universal agreement that if this goes on through the general election it can only do the labour party serious damage. there are signs that the two men appreciate the dangers and both want to put a lid on all the speculation. but with probably only four months to the next election  that looks like being a particularly difficult trick to pull off.',\n",
       " 'politics')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random article\n",
    "df['Text'][90], df['Category'][90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f5f91b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['business', 'tech', 'politics', 'sport', 'entertainment'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Category'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4986c0b5",
   "metadata": {},
   "source": [
    "###  Tokenize, clean and lowercase the documents using gensim.utils.simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26463140",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df['Text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbbbd3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield gensim.utils.simple_preprocess(str(sentence), deacc = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8989affb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words = list(sent_to_words(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6420f309",
   "metadata": {},
   "source": [
    "### Lemmatize the documents to reduce the total number of unique words in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "609e0d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable = ['parser', 'ner'])\n",
    "\n",
    "def lemmatize(texts, allowed_pos = ['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(' '.join(sent))\n",
    "        texts_out.append(' '.join([token.lemma_ for token in doc if token.pos_ in allowed_pos]))\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b763e924",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lemmatized = lemmatize(data_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79834f2",
   "metadata": {},
   "source": [
    "### Create document term matrix using sklearn's  CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33b9d2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(lowercase = True, stop_words = 'english', min_df = 5, token_pattern = '[a-zA-Z0-9]{3,}')\n",
    "\n",
    "data_vectorized = vectorizer.fit_transform(data_lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f4c92e",
   "metadata": {},
   "source": [
    "### Build LDA model with sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f375fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda_model = LatentDirichletAllocation(n_components = 5, learning_method = 'online', max_iter = 10, batch_size = 128, \n",
    "                                      n_jobs = -1, random_state = 64)\n",
    "\n",
    "lda_output = lda_model.fit_transform(data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f31be694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.663300</td>\n",
       "      <td>0.019783</td>\n",
       "      <td>0.001666</td>\n",
       "      <td>0.313592</td>\n",
       "      <td>0.001660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.994099</td>\n",
       "      <td>0.001471</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.001475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.641186</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.355573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.997008</td>\n",
       "      <td>0.000745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.869090</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>0.020906</td>\n",
       "      <td>0.038107</td>\n",
       "      <td>0.070481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4\n",
       "0  0.663300  0.019783  0.001666  0.313592  0.001660\n",
       "1  0.994099  0.001471  0.001479  0.001476  0.001475\n",
       "2  0.641186  0.001072  0.001078  0.001090  0.355573\n",
       "3  0.000747  0.000752  0.000748  0.997008  0.000745\n",
       "4  0.869090  0.001416  0.020906  0.038107  0.070481"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(lda_output).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83a185c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_components</th>\n",
       "      <th>Log Likelihood</th>\n",
       "      <th>Perplexity</th>\n",
       "      <th>Coherence Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>-1591501.70</td>\n",
       "      <td>1481.73</td>\n",
       "      <td>0.4122 ± 0.0788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>-1578413.04</td>\n",
       "      <td>1395.38</td>\n",
       "      <td>0.4683 ± 0.0827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>-1564565.07</td>\n",
       "      <td>1309.50</td>\n",
       "      <td>0.5497 ± 0.0787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>-1580467.74</td>\n",
       "      <td>1408.60</td>\n",
       "      <td>0.5148 ± 0.1292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>-1563982.13</td>\n",
       "      <td>1306.00</td>\n",
       "      <td>0.5312 ± 0.1291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_components  Log Likelihood  Perplexity  Coherence Score\n",
       "0             3     -1591501.70     1481.73  0.4122 ± 0.0788\n",
       "1             4     -1578413.04     1395.38  0.4683 ± 0.0827\n",
       "2             5     -1564565.07     1309.50  0.5497 ± 0.0787\n",
       "3             6     -1580467.74     1408.60  0.5148 ± 0.1292\n",
       "4             7     -1563982.13     1306.00  0.5312 ± 0.1291"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We know before hand that the dataset contains 5 categories. Let's check the Log Likelihood, Perplexity and Coherence Score for different\n",
    "# values of n_components and select number of topics for LDA accordingly.\n",
    "\n",
    "# Coherence score for a sklearn LatentDirichletAllocation model can be found out using tmtoolkit library.\n",
    "\n",
    "metrics = pd.DataFrame(columns = ['n_components', 'Log Likelihood', 'Perplexity', 'Coherence Score'])\n",
    "\n",
    "for i in range(3, 8):\n",
    "    lda_model = LatentDirichletAllocation(n_components = i, learning_method = 'online', max_iter = 10, batch_size = 128, \n",
    "                                          n_jobs = -1, random_state = 64)\n",
    "    lda_model.fit_transform(data_vectorized)\n",
    "    c_v = metric_coherence_gensim(measure = 'c_v',\n",
    "                                  top_n = 10,\n",
    "                                  topic_word_distrib = lda_model.components_,\n",
    "                                  dtm = data_vectorized,\n",
    "                                  vocab = np.array(vectorizer.get_feature_names()),\n",
    "                                  texts = [doc.split() for doc in data_lemmatized],\n",
    "                                  return_mean = False)\n",
    "    c_v_text = f'{np.round(np.mean(c_v), 4)} ± {np.round(np.std(c_v), 4)}'\n",
    "    metrics.loc[len(metrics)] = [i, np.round(lda_model.score(data_vectorized), 2), np.round(lda_model.perplexity(data_vectorized), 2), \n",
    "                                 c_v_text]\n",
    "    \n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1169db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lda = LatentDirichletAllocation(n_components = 5, learning_method = 'online', max_iter = 10, batch_size = 128, \n",
    "                                     n_jobs = -1, random_state = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fd96972",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_output = best_lda.fit_transform(data_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aca2a8",
   "metadata": {},
   "source": [
    "### Display topics distribution for documents in the dataframe and also the dominant topic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c36ba31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic0</th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Topic4</th>\n",
       "      <th>Dominant Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.663300</td>\n",
       "      <td>0.019783</td>\n",
       "      <td>0.001666</td>\n",
       "      <td>0.313592</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.994099</td>\n",
       "      <td>0.001471</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.001475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.641186</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.355573</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.997008</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.869090</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>0.020906</td>\n",
       "      <td>0.038107</td>\n",
       "      <td>0.070481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002234</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>0.887216</td>\n",
       "      <td>0.017022</td>\n",
       "      <td>0.091326</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001774</td>\n",
       "      <td>0.001772</td>\n",
       "      <td>0.992893</td>\n",
       "      <td>0.001774</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.082232</td>\n",
       "      <td>0.545914</td>\n",
       "      <td>0.127662</td>\n",
       "      <td>0.002578</td>\n",
       "      <td>0.241615</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.995911</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.131520</td>\n",
       "      <td>0.861627</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic0    Topic1    Topic2    Topic3    Topic4  Dominant Topic\n",
       "0  0.663300  0.019783  0.001666  0.313592  0.001660               0\n",
       "1  0.994099  0.001471  0.001479  0.001476  0.001475               0\n",
       "2  0.641186  0.001072  0.001078  0.001090  0.355573               0\n",
       "3  0.000747  0.000752  0.000748  0.997008  0.000745               3\n",
       "4  0.869090  0.001416  0.020906  0.038107  0.070481               0\n",
       "5  0.002234  0.002203  0.887216  0.017022  0.091326               2\n",
       "6  0.001774  0.001772  0.992893  0.001774  0.001786               2\n",
       "7  0.082232  0.545914  0.127662  0.002578  0.241615               1\n",
       "8  0.995911  0.001019  0.001022  0.001029  0.001019               0\n",
       "9  0.131520  0.861627  0.002277  0.002277  0.002299               1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = pd.DataFrame(lda_output, columns = ['Topic0', 'Topic1', 'Topic2', 'Topic3', 'Topic4'])\n",
    "topics['Dominant Topic'] = np.argmax(topics.values, axis = 1)\n",
    "topics.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f92fddc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    375\n",
       "0    342\n",
       "4    268\n",
       "3    258\n",
       "1    247\n",
       "Name: Dominant Topic, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics['Dominant Topic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca27b8e",
   "metadata": {},
   "source": [
    "### Let's check the top 20 words for each topic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8bb35b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_topics(vectorizer, lda_model, n_words = 20):\n",
    "    keywords = np.array(vectorizer.get_feature_names())\n",
    "    topic_keywords = []\n",
    "    for topic_weights in lda_model.components_:\n",
    "        top_keyword_locs = (-topic_weights).argsort()[:n_words]\n",
    "        topic_keywords.append(keywords.take(top_keyword_locs))\n",
    "    return np.array(topic_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bc9520e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic0</th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Topic4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>say</td>\n",
       "      <td>film</td>\n",
       "      <td>say</td>\n",
       "      <td>say</td>\n",
       "      <td>say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>year</td>\n",
       "      <td>good</td>\n",
       "      <td>win</td>\n",
       "      <td>use</td>\n",
       "      <td>government</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>company</td>\n",
       "      <td>award</td>\n",
       "      <td>game</td>\n",
       "      <td>people</td>\n",
       "      <td>election</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>market</td>\n",
       "      <td>year</td>\n",
       "      <td>year</td>\n",
       "      <td>mobile</td>\n",
       "      <td>party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>firm</td>\n",
       "      <td>say</td>\n",
       "      <td>play</td>\n",
       "      <td>phone</td>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rise</td>\n",
       "      <td>star</td>\n",
       "      <td>time</td>\n",
       "      <td>make</td>\n",
       "      <td>labour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sale</td>\n",
       "      <td>win</td>\n",
       "      <td>make</td>\n",
       "      <td>technology</td>\n",
       "      <td>plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>growth</td>\n",
       "      <td>include</td>\n",
       "      <td>good</td>\n",
       "      <td>service</td>\n",
       "      <td>tory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>economy</td>\n",
       "      <td>music</td>\n",
       "      <td>player</td>\n",
       "      <td>new</td>\n",
       "      <td>law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>share</td>\n",
       "      <td>actor</td>\n",
       "      <td>come</td>\n",
       "      <td>year</td>\n",
       "      <td>public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>price</td>\n",
       "      <td>band</td>\n",
       "      <td>just</td>\n",
       "      <td>user</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>country</td>\n",
       "      <td>number</td>\n",
       "      <td>think</td>\n",
       "      <td>game</td>\n",
       "      <td>minister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>business</td>\n",
       "      <td>make</td>\n",
       "      <td>team</td>\n",
       "      <td>net</td>\n",
       "      <td>make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rate</td>\n",
       "      <td>oscar</td>\n",
       "      <td>club</td>\n",
       "      <td>firm</td>\n",
       "      <td>tax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>month</td>\n",
       "      <td>release</td>\n",
       "      <td>world</td>\n",
       "      <td>music</td>\n",
       "      <td>tell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>economic</td>\n",
       "      <td>chart</td>\n",
       "      <td>match</td>\n",
       "      <td>work</td>\n",
       "      <td>issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>high</td>\n",
       "      <td>new</td>\n",
       "      <td>second</td>\n",
       "      <td>computer</td>\n",
       "      <td>claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>increase</td>\n",
       "      <td>album</td>\n",
       "      <td>final</td>\n",
       "      <td>software</td>\n",
       "      <td>campaign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fall</td>\n",
       "      <td>director</td>\n",
       "      <td>tell</td>\n",
       "      <td>digital</td>\n",
       "      <td>change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>expect</td>\n",
       "      <td>play</td>\n",
       "      <td>want</td>\n",
       "      <td>network</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topic0    Topic1  Topic2      Topic3      Topic4\n",
       "0        say      film     say         say         say\n",
       "1       year      good     win         use  government\n",
       "2    company     award    game      people    election\n",
       "3     market      year    year      mobile       party\n",
       "4       firm       say    play       phone      people\n",
       "5       rise      star    time        make      labour\n",
       "6       sale       win    make  technology        plan\n",
       "7     growth   include    good     service        tory\n",
       "8    economy     music  player         new         law\n",
       "9      share     actor    come        year      public\n",
       "10     price      band    just        user         new\n",
       "11   country    number   think        game    minister\n",
       "12  business      make    team         net        make\n",
       "13      rate     oscar    club        firm         tax\n",
       "14     month   release   world       music        tell\n",
       "15  economic     chart   match        work       issue\n",
       "16      high       new  second    computer       claim\n",
       "17  increase     album   final    software    campaign\n",
       "18      fall  director    tell     digital      change\n",
       "19    expect      play    want     network     general"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(show_topics(vectorizer, best_lda, n_words = 20).T, columns = ['Topic0', 'Topic1', 'Topic2', 'Topic3', 'Topic4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab93e929",
   "metadata": {},
   "source": [
    "### Visualize the topic model with  pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959bd2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyLDAvis import sklearn as LDAsklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "panel = LDAsklearn.prepare(best_lda, data_vectorized, vectorizer, mds = 'tsne')\n",
    "panel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd4b853",
   "metadata": {},
   "source": [
    "## News article recommendation using topic modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72573ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get topc distribution of a given text using the fitted LDA model\n",
    "\n",
    "def text_2_topics(text):\n",
    "    text = list(sent_to_words([text]))\n",
    "    lemmatized = lemmatize(text)\n",
    "    vectorized = vectorizer.transform(lemmatized)\n",
    "    lda_output = best_lda.transform(vectorized)\n",
    "    return lda_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1b7b6a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit NearestNeighbors on the LDA ouptput to create a vector database\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "neighbors = NearestNeighbors(n_neighbors = 5, n_jobs = -1)\n",
    "neighbors.fit(lda_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "88306895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to summarize document into 3 sentences using sumy package. \n",
    "\n",
    "def summarize(para, sentence_count = 3): \n",
    "    from sumy.parsers.plaintext import PlaintextParser\n",
    "    from sumy.nlp.tokenizers import Tokenizer\n",
    "    from sumy.summarizers.lsa import LsaSummarizer as Summarizer\n",
    "    from sumy.nlp.stemmers import Stemmer\n",
    "    from sumy.utils import get_stop_words\n",
    "\n",
    "    LANGUAGE = 'english'\n",
    "    SENTENCES_COUNT = sentence_count\n",
    "\n",
    "    parser = PlaintextParser.from_string(para, Tokenizer(LANGUAGE))\n",
    "    stemmer = Stemmer(LANGUAGE)\n",
    "\n",
    "    summarizer = Summarizer(stemmer)\n",
    "    summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "    for sentence in summarizer(parser.document, SENTENCES_COUNT):\n",
    "        print(str(sentence).capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fdedf614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check recommendations to a random news article\n",
    "\n",
    "def random_example():    \n",
    "    i = np.random.randint(1, len(df))\n",
    "    summarize(df.loc[i, 'Text'], sentence_count = 3)\n",
    "    print(df['Category'][i], end = '\\n\\n\\n')\n",
    "    print('\\t\\t\\t\\t\\t\\t\\t\\t News Recommendations', end = '\\n\\n')\n",
    "\n",
    "    distances, indices = neighbors.kneighbors(text_2_topics(df['Text'][i])[0].reshape(1, -1))\n",
    "\n",
    "    for ind in indices[0][1:]:\n",
    "        summarize(df.loc[ind, 'Text'], sentence_count = 3)\n",
    "        print('--------------------------------------------------', end = '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7fedf5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following the fascination with the writing of salam pax - not his real name - he began a regular column in the guardian newspaper and was given a crash course in documentary film-making.\n",
      "For the film he travelled iraq to document the changing landscape of the country and the problems it has faced since the invasion  speaking to ordinary iraqis about their experiences.\n",
      "Rasheed said the title was refers to the isolation felt by iraqis under saddam s regime and the difficult time the country is now experiencing.\n",
      "entertainment\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\t News Recommendations\n",
      "\n",
      "Sizzla  whose real name is miguel collins  has released 25 albums since 1995 and is credited with taking dancehall music back to its reggae origins.\n",
      "Many jamaican entertainers have appeared before the courts for use of profanity in recent years but they usually receive a verbal warning  a suspended sentence or community service.\n",
      "Sizzla s uk tour was cancelled after scotland yard s racial and violent crime taskforce announced it was examining lyrics by eight reggae artists.\n",
      "--------------------------------------------------\n",
      "\n",
      "Gibson and his icon productions partner bruce davey said they would not be campaigning in print  radio or tv for success at the oscars in february.\n",
      "Over recent years  marketing films to the members of the academy of motion picture arts and sciences has become a multi-million dollar industry.\n",
      "Academy president frank pierson praised gibson s move for working to restore the oscars as a  celebration and appreciation of excellence   and resisting the  crass commercialisation that was threatening the integrity of the award .\n",
      "--------------------------------------------------\n",
      "\n",
      "The she hate me director urged students at his old atlanta university  morehouse college  to seek  gatekeeper positions  behind the scenes.\n",
      "Returning to his old university  which educates only african american students  lee discussed the challenges facing black people in the entertainment industry.\n",
      "He told aspiring young film-makers in the audience not to ignore non-traditional routes to getting a movie made  including raising funds independently and releasing films straight to dvd.\n",
      "--------------------------------------------------\n",
      "\n",
      "The performer s record label sony bmg has withdrawn the video and issued replacements to television stations.\n",
      "Alcoholism and domestic violence are among the other topics dealt with in his songs  half of which have been written with robbie williams  former collaborator  guy chambers.\n",
      "Mcfadden  who quit chart-topping group westlife in march  went to number one in september with his first solo single real to me.\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25299271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d9f817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea021c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef3e070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6faa251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50ef100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0edaf04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a8365e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30837219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebb42b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d1e3fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
